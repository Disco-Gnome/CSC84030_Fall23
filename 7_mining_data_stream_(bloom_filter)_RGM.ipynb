{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Disco-Gnome/CSC84030_Fall23/blob/main/7_mining_data_stream_(bloom_filter)_RGM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId"
      },
      "source": [
        "In this Colab we just need to install a [bloom_filter](https://github.com/hiway/python-bloom-filter), a Python library which offers an implementations of Bloom filters.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-qHai2252mI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679118a6-e856-4fe9-f232-990222054ae4"
      },
      "source": [
        "!pip install bloom_filter"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bloom_filter\n",
            "  Downloading bloom_filter-1.3.3-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: bloom_filter\n",
            "Successfully installed bloom_filter-1.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAYRX2PMm0L6"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO_IcxgquzhI"
      },
      "source": [
        "From the NLTK (Natural Language ToolKit) library, we import a large list of English dictionary words, commonly used by the very first spell-checking programs in Unix-like operating systems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xz3f79crEEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f31fdb-c817-4d84-a727-5d141219b076"
      },
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "\n",
        "from nltk.corpus import words\n",
        "word_list = words.words()\n",
        "print(f'Dictionary length: {len(word_list)}')\n",
        "print(word_list[:15])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary length: 236736\n",
            "['A', 'a', 'aa', 'aal', 'aalii', 'aam', 'Aani', 'aardvark', 'aardwolf', 'Aaron', 'Aaronic', 'Aaronical', 'Aaronite', 'Aaronitic', 'Aaru']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csbQXPUFUMob"
      },
      "source": [
        "Then we load another dataset from the NLTK Corpora collection: ```movie_reviews```.\n",
        "\n",
        "The movie reviews are categorized between *positive* and *negative*, so we construct a list of words (usually called **bag of words**) for each category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwgRhMT1UNUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e5f95b-e7ea-4d65-e1d2-cbe32ad7fcac"
      },
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "nltk.download('movie_reviews')\n",
        "\n",
        "neg_reviews = []\n",
        "pos_reviews = []\n",
        "\n",
        "for fileid in movie_reviews.fileids('neg'):\n",
        "  neg_reviews.extend(movie_reviews.words(fileid))\n",
        "for fileid in movie_reviews.fileids('pos'):\n",
        "  pos_reviews.extend(movie_reviews.words(fileid))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaF2A_j_nC7"
      },
      "source": [
        "### Your task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrHJptH3Tb-3"
      },
      "source": [
        "In this Colab, you will develop a very simplistic spell-checker.  By no means you should think of using it for a real-world use case, but it is an interesting exercise to highlight the strenghts and weaknesses of Bloom Filters!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK3WyXaPsa5q"
      },
      "source": [
        "from bloom_filter import BloomFilter\n",
        "\n",
        "word_filter = BloomFilter(max_elements=236736)\n",
        "\n",
        "for word in word_list:\n",
        "  word_filter.add(word)\n",
        "\n",
        "word_set = set(word_list)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddqg0odiaSRg"
      },
      "source": [
        "If you executed the cell above, you now have 3 different variables in your scope:\n",
        "\n",
        "1.   ```word_list```, a Python list containing the English dictionary (in case insensitive order)\n",
        "2.   ```word_filter```, a Bloom filter where we have already added all the words in the English dictionary\n",
        "3.   ```word_set```, a [Python set](https://docs.python.org/3.6/library/stdtypes.html#set-types-set-frozenset) built from the same list of words in the English dictionary\n",
        "\n",
        "Let's inspect the size of each data structure using the [getsizeof()](https://docs.python.org/3/library/sys.html#sys.getsizeof) method!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVLxu20maRLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030c5784-ddf4-4078-d075-7c8ba5ab9324"
      },
      "source": [
        "#Inspecting byte size of alternative structures\n",
        "from sys import getsizeof\n",
        "\n",
        "print(f'Size of word_list (in bytes): {getsizeof(word_list)}')\n",
        "print(f'Size of word_filter (in bytes): {getsizeof(word_filter)}')\n",
        "print(f'Size of word_set (in bytes): {getsizeof(word_set)}')\n",
        "print('\\nFrom largest to smallest: set, list, filter')\n",
        "print('\\nA Bloom Filter takes up a mere 48 bytes: 2.34e-3% as much memory as a list, and 5.72e-4% as much memory as a set.')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of word_list (in bytes): 2055512\n",
            "Size of word_filter (in bytes): 48\n",
            "Size of word_set (in bytes): 8388824\n",
            "\n",
            "From largest to smallest: set, list, filter\n",
            "\n",
            "A Bloom Filter takes up a mere 48 bytes: 2.34e-3% as much memory as a list, and 5.72e-4% as much memory as a set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbQzd4czlT3h"
      },
      "source": [
        "You should have noticed how efficient is the Bloom filter in terms of memory footprint!\n",
        "\n",
        "Now let's find out how fast is the main operation for which we construct Bloom filters: *membership testing*. To do so, we will use the ```%timeit``` IPython magic command, which times the repeated execution of a single Python statement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq7I6kJfwXy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c0c37f8-eca7-4778-d6fa-fa04397a38d7"
      },
      "source": [
        "#Timing queries on various structures\n",
        "\n",
        "%timeit -r 3 \"California\" in word_list\n",
        "%timeit -r 3 \"California\" in word_filter\n",
        "%timeit -r 3 \"California\" in word_set\n",
        "\n",
        "print('\\nFrom fastest to slowest: set, filter, list.')\n",
        "print('\\nQuerying a Bloom Filter is roughly 3,264% times faster than querying a list, but ~22,790% slower than querying a set.')\n",
        "print('\\nFrom these last 2 cells, we observe that a Bloom Filter splits the difference, being faster to query than a list,\\nthough slower to query than a set. But, it also uses much less memory to store than either a list or set.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "413 µs ± 3.98 µs per loop (mean ± std. dev. of 3 runs, 1000 loops each)\n",
            "16.4 µs ± 4.89 µs per loop (mean ± std. dev. of 3 runs, 100000 loops each)\n",
            "76.3 ns ± 23.7 ns per loop (mean ± std. dev. of 3 runs, 10000000 loops each)\n",
            "\n",
            "From fastest to slowest: set, filter, list.\n",
            "\n",
            "Querying a Bloom Filter is roughly 3,264% times faster than querying a list, but ~22,790% slower than querying a set.\n",
            "\n",
            "From these last 2 cells, we observe that a Bloom Filter splits the difference, being faster to query than a list,\n",
            "though slower to query than a set. But, it also uses much less memory to store than either a list or set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq2LVgEVnI_R"
      },
      "source": [
        "Notice the performance gap between linear search on a list, multiple hash computations in a Bloom filter, and a single hash computation in a native Python ```Set()```.\n",
        "\n",
        "We now have all the building blocks required to build our spell-checker, and we understand the performance tradeoffs of each data structure we chose. Write a function that takes as arguments (1) a list of words, and (2) any of the 3 dictionary data structures we constructed. The function must return the number of words which **do not appear** in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTT-6rQcnibH"
      },
      "source": [
        "#Define our function\n",
        "def countNotInDict(words_object, dict_struct):\n",
        "    assert type(words_object) == list\n",
        "    count_not_found = 0\n",
        "    for word in words_object:\n",
        "        if word not in dict_struct:\n",
        "            count_not_found = count_not_found + 1\n",
        "    return count_not_found\n",
        "    del count_not_found"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test our function\n",
        "test_list = ['A', 'aardvark', 'Aaru', 'asdf1234', 'jkl;5678']\n",
        "assert countNotInDict(test_list, word_filter) == 2\n",
        "print(f'Test words not found in dictionary: {countNotInDict(test_list, word_filter)}\\n')\n",
        "\n",
        "%timeit -r 3 countNotInDict(test_list, word_list)\n",
        "%timeit -r 3 countNotInDict(test_list, word_filter)\n",
        "%timeit -r 3 countNotInDict(test_list, word_set)\n",
        "\n",
        "print('\\nFrom fastest to slowest: set, filter, list. Same as above.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM9LB4j_TEFL",
        "outputId": "3dfb9629-0d81-4219-f362-ce3df5d95036"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test words not found in dictionary: 2\n",
            "\n",
            "10.9 ms ± 2.42 ms per loop (mean ± std. dev. of 3 runs, 100 loops each)\n",
            "44 µs ± 637 ns per loop (mean ± std. dev. of 3 runs, 10000 loops each)\n",
            "474 ns ± 6.13 ns per loop (mean ± std. dev. of 3 runs, 1000000 loops each)\n",
            "\n",
            "From fastest to slowest: set, filter, list. Same as above.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run our function\n",
        "print('_____Running Function on negative Reviews Words List_____')\n",
        "print(f'Words in negative reviews: {len(neg_reviews)}')\n",
        "print(f'Words in negative reviews not found in dictionary: {(countNotInDict(neg_reviews, word_set))}')\n",
        "print(f'Proportion of words in negative reviews not found in dictionary: {round(100*countNotInDict(neg_reviews, word_set)/len(neg_reviews),2)}%')\n",
        "print('\\n_____Running Function on Positive Reviews Words List_____')\n",
        "print(f'Words in positive reviews: {len(pos_reviews)}')\n",
        "print(f'Words in positive reviews not found in dictionary: {(countNotInDict(pos_reviews, word_set))}')\n",
        "print(f'Proportion of words in positive reviews not found in dictionary: {round(100*countNotInDict(pos_reviews, word_set)/len(neg_reviews),2)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4zSqjMyVvVG",
        "outputId": "b06995c0-d6b5-4bcc-8801-eecd936da3b8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_____Testing Function on Negative Reviews Words List_____\n",
            "Words in negative reviews: 751256\n",
            "Words in negative reviews not found in dictionary: 210258\n",
            "Proportion of words in negative reviews not found in dictionary: 27.99%\n",
            "\n",
            "_____Testing Function on Positive Reviews Words List_____\n",
            "Words in positive reviews: 832564\n",
            "Words in positive reviews not found in dictionary: 232436\n",
            "Proportion of words in positive reviews not found in dictionary: 30.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIrXJyVNP2AI"
      },
      "source": [
        "#### **Submission Intruction:**\n",
        "\n",
        "#### Click File -> Download -> Download **.ipynb**, and upload the downloaded file to Blackboard."
      ]
    }
  ]
}